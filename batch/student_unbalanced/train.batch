#!/bin/bash

#SBATCH --job-name=train
#SBATCH --output=train.out
#SBATCH --error=train.err
#SBATCH -p gpu2
#SBATCH --gres=gpu:1
#SBATCH --time=8:00:00
#SBATCH --account=pi-glk
#SBATCH --mem-per-cpu=32000

# Proper way to load:
module unload python
module load Anaconda3/2018.12; \
source activate tf-gpu-1.12.0

cd /project2/glk/latens

epochs=300
latent_dim=2
batch_size=64
ae=student
dataset=unbalanced_mnist

echo "Starting training..."
python latens.py autoencoder -i data/$dataset/$dataset \
       --ae $ae \
       -m models/${dataset}_${ae}_e${epochs}_L${latent_dim}_b${batch_size} \
       -e $epochs -L $latent_dim -b $batch_size \
       --overwrite --keras-verbose 2
echo "Finished."
